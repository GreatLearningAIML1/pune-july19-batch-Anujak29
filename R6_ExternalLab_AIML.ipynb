{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_ExternalLab_AIML (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYk8NG3yOIT9",
        "colab_type": "text"
      },
      "source": [
        "### A MNIST-like fashion product database\n",
        "\n",
        "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFO6PuxzOIT_",
        "colab_type": "text"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoazjSArNY-W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efNjNImfOIUC",
        "colab_type": "code",
        "outputId": "2afbdedd-0368-4eab-8bab-2f33548614b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV5WrB-geDBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcoZBStrOIUQ",
        "colab_type": "text"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA1WsFSeOIUS",
        "colab_type": "code",
        "outputId": "de6ebc64-05b8-4aab-98cc-5a96ddd1cd1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnbx7TyQOIUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbiHj5YPOIUc",
        "colab_type": "code",
        "outputId": "04172577-38ca-448f-d428-b67b1b4f7e01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(testY[0:5])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDAYzkwyOIUj",
        "colab_type": "text"
      },
      "source": [
        "### Convert both training and testing labels into one-hot vectors.\n",
        "\n",
        "**Hint:** check **tf.keras.utils.to_categorical()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBlfYlANOIUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
        "testY = tf.keras.utils.to_categorical(testY, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RHV3b9mzOIUq",
        "colab_type": "code",
        "outputId": "4c8ad760-ba5d-419c-d9f0-309ba68a8470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(trainY.shape)\n",
        "print('First 5 examples now are: ', trainY[0:5])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "('First 5 examples now are: ', array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwhQ8e7VOIUw",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the data\n",
        "\n",
        "Plot first 10 images in the triaining set and their labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9hscTprhJ2K",
        "colab_type": "code",
        "outputId": "3cf1c4fc-3184-4482-ddce-06c7d465443c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# visualizing the first 10 images in the dataset and their labels\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 1))\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(trainX[i].reshape(28, 28), cmap=\"gray\")\n",
        "    plt.axis('off')\n",
        "    print('label for each of the below image: %s' % (np.argmax(trainY[0:10][i])))\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label for each of the below image: 9\n",
            "label for each of the below image: 0\n",
            "label for each of the below image: 0\n",
            "label for each of the below image: 3\n",
            "label for each of the below image: 0\n",
            "label for each of the below image: 2\n",
            "label for each of the below image: 7\n",
            "label for each of the below image: 2\n",
            "label for each of the below image: 5\n",
            "label for each of the below image: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAABSCAYAAABwglFkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRVEURVF88P8A0wyYl+ZpGWEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4TbJGeSOIU4",
        "colab_type": "text"
      },
      "source": [
        "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac06XZZTOIU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.backend import backend"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PChCQ8ch35E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Build the model \n",
        "# Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "# Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyafLtcpj5PJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
        "\n",
        "# Comile the model\n",
        "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQpLv3aOIU_",
        "colab_type": "text"
      },
      "source": [
        "### Execute the model using model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O59C_-IgOIVB",
        "colab_type": "code",
        "outputId": "4a647022-da8e-4192-86e1-e9239bd99fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=30)\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 4s 71us/sample - loss: 6150.1695 - accuracy: 0.7375 - val_loss: 4236.3978 - val_accuracy: 0.7860\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 4884.1101 - accuracy: 0.7771 - val_loss: 8756.7917 - val_accuracy: 0.6323\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 4688.5255 - accuracy: 0.7864 - val_loss: 6904.9165 - val_accuracy: 0.7909\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 4494.1222 - accuracy: 0.7911 - val_loss: 3420.7534 - val_accuracy: 0.8119\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 4418.4293 - accuracy: 0.7957 - val_loss: 3250.4258 - val_accuracy: 0.8019\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 4478.3483 - accuracy: 0.7947 - val_loss: 3879.0837 - val_accuracy: 0.7746\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 4381.2286 - accuracy: 0.7980 - val_loss: 7673.9011 - val_accuracy: 0.7337\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 4308.1680 - accuracy: 0.7999 - val_loss: 3959.5060 - val_accuracy: 0.8066\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 4225.9351 - accuracy: 0.7981 - val_loss: 6637.2919 - val_accuracy: 0.7543\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 4208.6372 - accuracy: 0.8008 - val_loss: 15055.7947 - val_accuracy: 0.6738\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 4352.4833 - accuracy: 0.7999 - val_loss: 3883.7465 - val_accuracy: 0.7894\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 4280.1352 - accuracy: 0.8021 - val_loss: 2995.7838 - val_accuracy: 0.8274\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 4198.4513 - accuracy: 0.8019 - val_loss: 8059.1069 - val_accuracy: 0.7184\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 4220.1290 - accuracy: 0.8026 - val_loss: 3146.2568 - val_accuracy: 0.8128\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 4185.9112 - accuracy: 0.8043 - val_loss: 4008.0176 - val_accuracy: 0.7931\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 4240.6744 - accuracy: 0.8019 - val_loss: 5412.3190 - val_accuracy: 0.7383\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 4350.2861 - accuracy: 0.8036 - val_loss: 3828.2217 - val_accuracy: 0.8177\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 4260.7201 - accuracy: 0.8039 - val_loss: 5224.6910 - val_accuracy: 0.7479\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 4122.6273 - accuracy: 0.8047 - val_loss: 4361.9138 - val_accuracy: 0.7796\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 4202.6261 - accuracy: 0.8059 - val_loss: 3426.1902 - val_accuracy: 0.8161\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 4138.4603 - accuracy: 0.8069 - val_loss: 6265.5656 - val_accuracy: 0.7537\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 4164.7967 - accuracy: 0.8058 - val_loss: 4223.9150 - val_accuracy: 0.8067\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 4208.3580 - accuracy: 0.8038 - val_loss: 6682.9185 - val_accuracy: 0.7377\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 4219.0322 - accuracy: 0.8080 - val_loss: 5723.1180 - val_accuracy: 0.7725\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 4s 62us/sample - loss: 4072.8945 - accuracy: 0.8052 - val_loss: 3759.1566 - val_accuracy: 0.7951\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 4134.3613 - accuracy: 0.8061 - val_loss: 5289.6605 - val_accuracy: 0.7683\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 4067.5041 - accuracy: 0.8077 - val_loss: 3025.9947 - val_accuracy: 0.8222\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 4168.7847 - accuracy: 0.8061 - val_loss: 4172.4422 - val_accuracy: 0.7830\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 4113.4524 - accuracy: 0.8080 - val_loss: 4050.5994 - val_accuracy: 0.7787\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 4113.1957 - accuracy: 0.8086 - val_loss: 3747.8642 - val_accuracy: 0.7916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f37a92c0c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqwkqPinm9H7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "041ce835-2e17-4d9e-b565-21aaea013bd0"
      },
      "source": [
        "score = model.evaluate(trainX, trainY, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2903.9981712972003, 0.81811666]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdzDtGwDOIVF",
        "colab_type": "text"
      },
      "source": [
        "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kndfpdidOIVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "# Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "# Add Dense Layer which provides 10 Outputs after applying softmax\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqH1ja5ClYqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
        "# Comile the model\n",
        "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd69NZR7lZMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwk3T5LJOIVN",
        "colab_type": "text"
      },
      "source": [
        "### Execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNLR8tcBOIVP",
        "colab_type": "code",
        "outputId": "19cd330b-0ac1-4c59-a688-f74f9bd6d92d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50,\n",
        "          batch_size = 32)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 0.5558 - accuracy: 0.8087 - val_loss: 0.5220 - val_accuracy: 0.8260\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.4875 - accuracy: 0.8324 - val_loss: 0.5048 - val_accuracy: 0.8250\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 19s 320us/sample - loss: 0.4699 - accuracy: 0.8370 - val_loss: 0.5056 - val_accuracy: 0.8381\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 11s 185us/sample - loss: 0.4604 - accuracy: 0.8414 - val_loss: 0.5163 - val_accuracy: 0.8306\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 17s 284us/sample - loss: 0.4572 - accuracy: 0.8413 - val_loss: 0.4868 - val_accuracy: 0.8373\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 9s 153us/sample - loss: 0.4523 - accuracy: 0.8417 - val_loss: 0.4785 - val_accuracy: 0.8387\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4487 - accuracy: 0.8439 - val_loss: 0.5050 - val_accuracy: 0.8315\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4469 - accuracy: 0.8440 - val_loss: 0.4951 - val_accuracy: 0.8352\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4432 - accuracy: 0.8462 - val_loss: 0.5094 - val_accuracy: 0.8280\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4421 - accuracy: 0.8456 - val_loss: 0.5071 - val_accuracy: 0.8336\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4401 - accuracy: 0.8466 - val_loss: 0.4977 - val_accuracy: 0.8364\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4391 - accuracy: 0.8465 - val_loss: 0.4858 - val_accuracy: 0.8378\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4351 - accuracy: 0.8479 - val_loss: 0.5169 - val_accuracy: 0.8353\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4339 - accuracy: 0.8480 - val_loss: 0.5064 - val_accuracy: 0.8406\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 16s 267us/sample - loss: 0.4321 - accuracy: 0.8471 - val_loss: 0.5016 - val_accuracy: 0.8347\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 15s 254us/sample - loss: 0.4336 - accuracy: 0.8484 - val_loss: 0.5082 - val_accuracy: 0.8306\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4313 - accuracy: 0.8488 - val_loss: 0.5274 - val_accuracy: 0.8381\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 9s 154us/sample - loss: 0.4311 - accuracy: 0.8487 - val_loss: 0.5197 - val_accuracy: 0.8297\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4283 - accuracy: 0.8488 - val_loss: 0.5014 - val_accuracy: 0.8376\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 10s 163us/sample - loss: 0.4263 - accuracy: 0.8504 - val_loss: 0.5075 - val_accuracy: 0.8272\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4284 - accuracy: 0.8495 - val_loss: 0.5002 - val_accuracy: 0.8332\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4303 - accuracy: 0.8493 - val_loss: 0.4856 - val_accuracy: 0.8347\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.4253 - accuracy: 0.8497 - val_loss: 0.4885 - val_accuracy: 0.8393\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 11s 191us/sample - loss: 0.4249 - accuracy: 0.8514 - val_loss: 0.5016 - val_accuracy: 0.8343\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4270 - accuracy: 0.8503 - val_loss: 0.4919 - val_accuracy: 0.8386\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4271 - accuracy: 0.8496 - val_loss: 0.5185 - val_accuracy: 0.8379\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4219 - accuracy: 0.8514 - val_loss: 0.4930 - val_accuracy: 0.8389\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 9s 158us/sample - loss: 0.4248 - accuracy: 0.8514 - val_loss: 0.4919 - val_accuracy: 0.8390\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 14s 238us/sample - loss: 0.4194 - accuracy: 0.8519 - val_loss: 0.5190 - val_accuracy: 0.8331\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4226 - accuracy: 0.8515 - val_loss: 0.5042 - val_accuracy: 0.8362\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 9s 155us/sample - loss: 0.4226 - accuracy: 0.8500 - val_loss: 0.5076 - val_accuracy: 0.8366\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 15s 248us/sample - loss: 0.4209 - accuracy: 0.8519 - val_loss: 0.4832 - val_accuracy: 0.8376\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4197 - accuracy: 0.8524 - val_loss: 0.4902 - val_accuracy: 0.8384\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 9s 149us/sample - loss: 0.4213 - accuracy: 0.8524 - val_loss: 0.5086 - val_accuracy: 0.8363\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4182 - accuracy: 0.8530 - val_loss: 0.5115 - val_accuracy: 0.8363\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4189 - accuracy: 0.8530 - val_loss: 0.5113 - val_accuracy: 0.8384\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4187 - accuracy: 0.8505 - val_loss: 0.4974 - val_accuracy: 0.8387\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4178 - accuracy: 0.8520 - val_loss: 0.5047 - val_accuracy: 0.8365\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 19s 318us/sample - loss: 0.4182 - accuracy: 0.8511 - val_loss: 0.5091 - val_accuracy: 0.8366\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 16s 272us/sample - loss: 0.4206 - accuracy: 0.8521 - val_loss: 0.4907 - val_accuracy: 0.8350\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 15s 251us/sample - loss: 0.4174 - accuracy: 0.8523 - val_loss: 0.5020 - val_accuracy: 0.8385\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 19s 321us/sample - loss: 0.4189 - accuracy: 0.8527 - val_loss: 0.5084 - val_accuracy: 0.8341\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 19s 319us/sample - loss: 0.4181 - accuracy: 0.8521 - val_loss: 0.5010 - val_accuracy: 0.8359\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 19s 323us/sample - loss: 0.4159 - accuracy: 0.8542 - val_loss: 0.5023 - val_accuracy: 0.8366\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 19s 315us/sample - loss: 0.4166 - accuracy: 0.8533 - val_loss: 0.5081 - val_accuracy: 0.8331\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 18s 302us/sample - loss: 0.4145 - accuracy: 0.8527 - val_loss: 0.5009 - val_accuracy: 0.8382\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 13s 217us/sample - loss: 0.4152 - accuracy: 0.8542 - val_loss: 0.5100 - val_accuracy: 0.8338\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4167 - accuracy: 0.8537 - val_loss: 0.5188 - val_accuracy: 0.8335\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 11s 180us/sample - loss: 0.4144 - accuracy: 0.8545 - val_loss: 0.4946 - val_accuracy: 0.8392\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 19s 316us/sample - loss: 0.4134 - accuracy: 0.8537 - val_loss: 0.5033 - val_accuracy: 0.8374\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f37aa424290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc3NtR73nZQX",
        "colab_type": "code",
        "outputId": "809d4a77-21fd-4d5d-d800-c5e96824b468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score = model.evaluate(trainX, trainY, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.39839513114690783, 0.8685333]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py-KwkmjOIVU",
        "colab_type": "text"
      },
      "source": [
        "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLXUE9jWOIVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create optimizer with non-default learning rate\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJUqA5T4OIVc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ3zC6_Mo_1G",
        "colab_type": "code",
        "outputId": "d0943dda-85a2-41d6-874e-25100abf0e71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50,\n",
        "          batch_size = 32)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.8747 - accuracy: 0.7022 - val_loss: 0.6811 - val_accuracy: 0.7678\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.6410 - accuracy: 0.7804 - val_loss: 0.6157 - val_accuracy: 0.7921\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.5884 - accuracy: 0.7970 - val_loss: 0.5834 - val_accuracy: 0.8026\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.5590 - accuracy: 0.8077 - val_loss: 0.5576 - val_accuracy: 0.8092\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.5439 - accuracy: 0.8133 - val_loss: 0.5440 - val_accuracy: 0.8130\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.5307 - accuracy: 0.8159 - val_loss: 0.5262 - val_accuracy: 0.8181\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.5190 - accuracy: 0.8223 - val_loss: 0.5266 - val_accuracy: 0.8199\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.5118 - accuracy: 0.8237 - val_loss: 0.5121 - val_accuracy: 0.8218\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.5042 - accuracy: 0.8263 - val_loss: 0.5117 - val_accuracy: 0.8219\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4974 - accuracy: 0.8296 - val_loss: 0.5096 - val_accuracy: 0.8238\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4931 - accuracy: 0.8299 - val_loss: 0.5029 - val_accuracy: 0.8264\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4890 - accuracy: 0.8316 - val_loss: 0.4980 - val_accuracy: 0.8266\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4823 - accuracy: 0.8332 - val_loss: 0.5003 - val_accuracy: 0.8260\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.4803 - accuracy: 0.8354 - val_loss: 0.4925 - val_accuracy: 0.8293\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.4760 - accuracy: 0.8367 - val_loss: 0.4859 - val_accuracy: 0.8290\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.4751 - accuracy: 0.8368 - val_loss: 0.4886 - val_accuracy: 0.8295\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4700 - accuracy: 0.8381 - val_loss: 0.5009 - val_accuracy: 0.8299\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.4691 - accuracy: 0.8394 - val_loss: 0.5017 - val_accuracy: 0.8311\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4666 - accuracy: 0.8395 - val_loss: 0.4794 - val_accuracy: 0.8301\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4621 - accuracy: 0.8419 - val_loss: 0.4829 - val_accuracy: 0.8336\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4630 - accuracy: 0.8403 - val_loss: 0.4784 - val_accuracy: 0.8332\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4616 - accuracy: 0.8421 - val_loss: 0.4734 - val_accuracy: 0.8328\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4581 - accuracy: 0.8424 - val_loss: 0.4739 - val_accuracy: 0.8328\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4572 - accuracy: 0.8434 - val_loss: 0.4771 - val_accuracy: 0.8331\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4575 - accuracy: 0.8433 - val_loss: 0.4738 - val_accuracy: 0.8348\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4554 - accuracy: 0.8428 - val_loss: 0.4778 - val_accuracy: 0.8343\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4523 - accuracy: 0.8433 - val_loss: 0.4737 - val_accuracy: 0.8349\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4526 - accuracy: 0.8434 - val_loss: 0.4688 - val_accuracy: 0.8357\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4480 - accuracy: 0.8469 - val_loss: 0.4768 - val_accuracy: 0.8338\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.4494 - accuracy: 0.8451 - val_loss: 0.4779 - val_accuracy: 0.8354\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 0.4490 - accuracy: 0.8448 - val_loss: 0.4762 - val_accuracy: 0.8348\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4464 - accuracy: 0.8475 - val_loss: 0.4657 - val_accuracy: 0.8366\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4445 - accuracy: 0.8474 - val_loss: 0.4682 - val_accuracy: 0.8370\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4458 - accuracy: 0.8460 - val_loss: 0.4720 - val_accuracy: 0.8351\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4432 - accuracy: 0.8480 - val_loss: 0.4731 - val_accuracy: 0.8358\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4424 - accuracy: 0.8481 - val_loss: 0.4734 - val_accuracy: 0.8359\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.4427 - accuracy: 0.8479 - val_loss: 0.4698 - val_accuracy: 0.8360\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4405 - accuracy: 0.8495 - val_loss: 0.4703 - val_accuracy: 0.8361\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4405 - accuracy: 0.8478 - val_loss: 0.4685 - val_accuracy: 0.8381\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4412 - accuracy: 0.8480 - val_loss: 0.4642 - val_accuracy: 0.8350\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4400 - accuracy: 0.8477 - val_loss: 0.4686 - val_accuracy: 0.8366\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4395 - accuracy: 0.8482 - val_loss: 0.4621 - val_accuracy: 0.8379\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 5s 76us/sample - loss: 0.4390 - accuracy: 0.8488 - val_loss: 0.4671 - val_accuracy: 0.8382\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4376 - accuracy: 0.8498 - val_loss: 0.4675 - val_accuracy: 0.8388\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4362 - accuracy: 0.8504 - val_loss: 0.4629 - val_accuracy: 0.8386\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4350 - accuracy: 0.8509 - val_loss: 0.4631 - val_accuracy: 0.8389\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4357 - accuracy: 0.8510 - val_loss: 0.4661 - val_accuracy: 0.8382\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.4342 - accuracy: 0.8509 - val_loss: 0.4712 - val_accuracy: 0.8384\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 0.4339 - accuracy: 0.8518 - val_loss: 0.4610 - val_accuracy: 0.8379\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 0.4322 - accuracy: 0.8508 - val_loss: 0.4619 - val_accuracy: 0.8401\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0c7c0d1d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnthBJBzfVuN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7a82f06-ec5b-4563-f05a-86bf7411ca96"
      },
      "source": [
        "score = model.evaluate(trainX, trainY, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.4121707010050615, 0.8606]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CSqKvpOIVk",
        "colab_type": "text"
      },
      "source": [
        "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGAad54JOIVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Reshape data from 2D to 1D -> 28x28 to 784\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "\n",
        "# Normalize the data\n",
        "model.add(tf.keras.layers.BatchNormalization())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ7oIymROIVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add 1st hidden layer\n",
        "model.add(tf.keras.layers.Dense(100, activation='sigmoid', name= \"Layer_1\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-O-fFxnOIVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add 2nd hidden layer\n",
        "model.add(tf.keras.layers.Dense(100, activation='sigmoid', name= \"Layer_2\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiP7IL52OIVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add 3rd hidden layer\n",
        "model.add(tf.keras.layers.Dense(10, activation='sigmoid', name= \"Layer_3\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtSFHowXquKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add OUTPUT layer\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax', name = \"Output\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12NJz6K8qzkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create optimizer with non-default learning rate\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP8I6tn5rD8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr2YsZV0OIV0",
        "colab_type": "text"
      },
      "source": [
        "## Review model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ojW6-oOIV2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "8334a19f-9165-49ba-82cc-7b2fb128ce82"
      },
      "source": [
        "\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape (Reshape)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "Layer_1 (Dense)              (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "Layer_2 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "Layer_3 (Dense)              (None, 10)                1010      \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 92,856\n",
            "Trainable params: 91,288\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH4lV6d2N-Cj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b329bc0e-feea-47ad-a1fc-6b72107a9802"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.layers.core.Reshape at 0x7f078c1cd450>,\n",
              " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7f078c1cd650>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f078b993190>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f0785f039d0>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f078b96ee90>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f0785f1b710>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfFGmbZLOIV5",
        "colab_type": "text"
      },
      "source": [
        "### Run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIkbMEN5OIV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36361a01-68f0-4380-bb8b-46e4c6d0b37d"
      },
      "source": [
        "model.fit(trainX, trainY, validation_data=(testX, testY), epochs=50,\n",
        "          batch_size = 32)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 1.8902 - accuracy: 0.3589 - val_loss: 1.4141 - val_accuracy: 0.5386\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 1.1712 - accuracy: 0.6063 - val_loss: 0.9508 - val_accuracy: 0.6550\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.8706 - accuracy: 0.6770 - val_loss: 0.7845 - val_accuracy: 0.7152\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.7437 - accuracy: 0.7264 - val_loss: 0.6854 - val_accuracy: 0.7436\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.6627 - accuracy: 0.7574 - val_loss: 0.6175 - val_accuracy: 0.7802\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.6005 - accuracy: 0.7869 - val_loss: 0.5674 - val_accuracy: 0.7984\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.5500 - accuracy: 0.8117 - val_loss: 0.5261 - val_accuracy: 0.8191\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.5120 - accuracy: 0.8256 - val_loss: 0.4963 - val_accuracy: 0.8237\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.4854 - accuracy: 0.8343 - val_loss: 0.4803 - val_accuracy: 0.8328\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.4622 - accuracy: 0.8416 - val_loss: 0.4618 - val_accuracy: 0.8408\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.4434 - accuracy: 0.8487 - val_loss: 0.4502 - val_accuracy: 0.8426\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.4254 - accuracy: 0.8552 - val_loss: 0.4364 - val_accuracy: 0.8456\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.4091 - accuracy: 0.8597 - val_loss: 0.4236 - val_accuracy: 0.8526\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.3936 - accuracy: 0.8651 - val_loss: 0.4113 - val_accuracy: 0.8572\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.3796 - accuracy: 0.8688 - val_loss: 0.4062 - val_accuracy: 0.8596\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.3705 - accuracy: 0.8736 - val_loss: 0.3966 - val_accuracy: 0.8620\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3590 - accuracy: 0.8762 - val_loss: 0.3980 - val_accuracy: 0.8615\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.3491 - accuracy: 0.8787 - val_loss: 0.3926 - val_accuracy: 0.8643\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.3420 - accuracy: 0.8809 - val_loss: 0.3784 - val_accuracy: 0.8679\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.3328 - accuracy: 0.8834 - val_loss: 0.3784 - val_accuracy: 0.8665\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.3254 - accuracy: 0.8860 - val_loss: 0.3665 - val_accuracy: 0.8716\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.3192 - accuracy: 0.8882 - val_loss: 0.3609 - val_accuracy: 0.8743\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.3096 - accuracy: 0.8908 - val_loss: 0.3600 - val_accuracy: 0.8733\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.3046 - accuracy: 0.8926 - val_loss: 0.3570 - val_accuracy: 0.8755\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2998 - accuracy: 0.8945 - val_loss: 0.3526 - val_accuracy: 0.8752\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2926 - accuracy: 0.8956 - val_loss: 0.3554 - val_accuracy: 0.8755\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2873 - accuracy: 0.8975 - val_loss: 0.3474 - val_accuracy: 0.8792\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2833 - accuracy: 0.8988 - val_loss: 0.3498 - val_accuracy: 0.8756\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.2775 - accuracy: 0.9004 - val_loss: 0.3587 - val_accuracy: 0.8778\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2739 - accuracy: 0.9024 - val_loss: 0.3486 - val_accuracy: 0.8784\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2681 - accuracy: 0.9040 - val_loss: 0.3455 - val_accuracy: 0.8822\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.2630 - accuracy: 0.9056 - val_loss: 0.3472 - val_accuracy: 0.8779\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2604 - accuracy: 0.9072 - val_loss: 0.3430 - val_accuracy: 0.8816\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.2557 - accuracy: 0.9098 - val_loss: 0.3439 - val_accuracy: 0.8824\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 6s 108us/sample - loss: 0.2536 - accuracy: 0.9095 - val_loss: 0.3447 - val_accuracy: 0.8815\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2481 - accuracy: 0.9108 - val_loss: 0.3494 - val_accuracy: 0.8813\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2444 - accuracy: 0.9115 - val_loss: 0.3473 - val_accuracy: 0.8826\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2418 - accuracy: 0.9137 - val_loss: 0.3511 - val_accuracy: 0.8803\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2391 - accuracy: 0.9129 - val_loss: 0.3608 - val_accuracy: 0.8757\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2365 - accuracy: 0.9148 - val_loss: 0.3454 - val_accuracy: 0.8824\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.2338 - accuracy: 0.9161 - val_loss: 0.3439 - val_accuracy: 0.8822\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2317 - accuracy: 0.9175 - val_loss: 0.3554 - val_accuracy: 0.8808\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 6s 104us/sample - loss: 0.2281 - accuracy: 0.9170 - val_loss: 0.3581 - val_accuracy: 0.8782\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 6s 102us/sample - loss: 0.2235 - accuracy: 0.9195 - val_loss: 0.3481 - val_accuracy: 0.8806\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2212 - accuracy: 0.9205 - val_loss: 0.3533 - val_accuracy: 0.8799\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2170 - accuracy: 0.9215 - val_loss: 0.3523 - val_accuracy: 0.8823\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.2168 - accuracy: 0.9224 - val_loss: 0.3529 - val_accuracy: 0.8817\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2118 - accuracy: 0.9252 - val_loss: 0.3614 - val_accuracy: 0.8817\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 6s 106us/sample - loss: 0.2131 - accuracy: 0.9224 - val_loss: 0.3556 - val_accuracy: 0.8816\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 6s 105us/sample - loss: 0.2057 - accuracy: 0.9259 - val_loss: 0.3480 - val_accuracy: 0.8833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0785cf7ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34AtaJsDHhMe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1166f2d-18f0-45e7-d522-b71a6e852eea"
      },
      "source": [
        "score = model.evaluate(trainX, trainY, verbose=0)\n",
        "print(score)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.16392865899205208, 0.9447]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJRILEHVHpPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Observation : Here , we can say that we have gradually increased the accuracy and reduced the test loss over multiple runs by adding Normalization, \n",
        "#tuning hyperparameters and by addition of the Hidden layers.\n",
        "#In the end,  we have succesfully reduced the the Test loss to 0.1639 and increased the test accuracy to 94.47%."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}