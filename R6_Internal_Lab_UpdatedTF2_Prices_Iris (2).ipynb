{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_Internal_Lab_UpdatedTF2_Prices_Iris.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "84Q8JfvaeZZ6"
      },
      "source": [
        "## Linear Classifier in TensorFlow \n",
        "Using Low Level API in Eager Execution mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sb7Epo0VOB58"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fHpCNRv1OB5-",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "#tf.enable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mjtb-EMcm5K0",
        "colab": {}
      },
      "source": [
        "#Enable Eager Execution if using tensflow version < 2.0\n",
        "#From tensorflow v2.0 onwards, Eager Execution will be enabled by default\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FAg_P3k8E-x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09e59045-c7f4-4a77-a837-cb9565311caa"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVnfQgrc8WVH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "193e6461-7fbb-4b4d-f5e0-62e55f09c3ac"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DxJDmJqqOB6K"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FhllFLyKOB6N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a55a02ea-f84f-40b7-e197-fe01481de2ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KiObW4V4SIOz",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B4yQKMiJOB6R",
        "colab": {}
      },
      "source": [
        "#dataset = np.loadtxt(\"/content/drive/My Drive/ANN Mahesh Anand/pima-indians-diabetes.data\", delimiter=\",\")\n",
        "data = pd.read_csv('/content/drive/My Drive/Internal Lab-6/prices.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fgkX6SEqOB6W"
      },
      "source": [
        "### Check all columns in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7K8pWsNQOB6X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d23da27-5f4d-4e00-a28a-3975c0ce7a2f"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([u'date', u'symbol', u'open', u'close', u'low', u'high', u'volume'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlV_vYbvuEE1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c8001c9-228d-4dae-ce64-95e51f618b5b"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(851264, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9V_grh2vOPQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "6c036d61-6d3b-4c1e-93ba-dd374d0ce461"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>symbol</th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-05 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-06 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-07 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-08 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-11 00:00:00</td>\n",
              "      <td>WLTW</td>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  date symbol        open  ...         low        high     volume\n",
              "0  2016-01-05 00:00:00   WLTW  123.430000  ...  122.309998  126.250000  2163600.0\n",
              "1  2016-01-06 00:00:00   WLTW  125.239998  ...  119.940002  125.540001  2386400.0\n",
              "2  2016-01-07 00:00:00   WLTW  116.379997  ...  114.930000  119.739998  2489500.0\n",
              "3  2016-01-08 00:00:00   WLTW  115.480003  ...  113.500000  117.440002  2006300.0\n",
              "4  2016-01-11 00:00:00   WLTW  117.010002  ...  114.089996  117.330002  1408600.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7dU6X7MpOB6c"
      },
      "source": [
        "### Drop columns `date` and  `symbol`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lh_6spSKOB6e",
        "colab": {}
      },
      "source": [
        "data = data.drop([\"date\", \"symbol\"], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xlwbUgTwOB6i",
        "outputId": "071b5486-739e-454f-a21b-c882dd839309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         open       close         low        high     volume\n",
              "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
              "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
              "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
              "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
              "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3DBv3WWYOB6q"
      },
      "source": [
        "### Consider only first 1000 rows in the dataset for building feature set and target set\n",
        "Target 'Volume' has very high values. Divide 'Volume' by 1000,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z_hG9rGBOB6s",
        "colab": {}
      },
      "source": [
        "data = data.iloc[:1000,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbivuJGQvC0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93ab4e15-625f-4539-e527-3fd8e346b21c"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO6PemHmvZov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data[\"volume\"] = data[\"volume\"]/1000000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LSKw4zGvm6N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "4ef54654-ed08-45f3-e5c5-9f25c0501e4f"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2.1636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2.3864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2.4895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2.0063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1.4086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         open       close         low        high  volume\n",
              "0  123.430000  125.839996  122.309998  126.250000  2.1636\n",
              "1  125.239998  119.980003  119.940002  125.540001  2.3864\n",
              "2  116.379997  114.949997  114.930000  119.739998  2.4895\n",
              "3  115.480003  116.620003  113.500000  117.440002  2.0063\n",
              "4  117.010002  114.970001  114.089996  117.330002  1.4086"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6kVJB4EwNId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = data.drop(\"volume\", axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rEXsST0wZ9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = data[\"volume\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M3UaApqYOB6x"
      },
      "source": [
        "### Divide the data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4LE4U8lTdQJq",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsszJSaqvxMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.30,random_state = 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVs4gnr-wrTf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "213cd8fa-2366-4bb9-bba0-5f32607a67ae"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(700, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oYK-aUuLbrz2"
      },
      "source": [
        "#### Convert Training and Test Data to numpy float32 arrays\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdQsDBqnwqaN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ce723f7-9a6d-45a1-dffe-67c31adb5ec3"
      },
      "source": [
        "X_train.dtypes\n",
        "y_train.dtypes"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ao-S0tQGcncz",
        "colab": {}
      },
      "source": [
        "X_train =np.array(X_train).astype('float32')\n",
        "X_test = np.array(X_test).astype('float32')\n",
        "y_train =np.array(y_train).astype('float32')\n",
        "y_test = np.array(y_test).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "im1ZegbDdKgv"
      },
      "source": [
        "### Normalize the data\n",
        "You can use Normalizer from sklearn.preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2EkKAy7fOB6y",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "transformer = Normalizer()\n",
        "X_train = transformer.fit_transform(X_train)\n",
        "X_test = transformer.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v6vE4eYCOB62"
      },
      "source": [
        "## Building the Model in tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "297_qja4OB7A"
      },
      "source": [
        "1.Define Weights and Bias, use tf.zeros to initialize weights and Bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euh_ACfCyhwr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d09018f7-7f22-4d06-9b43-44cf1d6b09ab"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(700,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7si7_Xaypi5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = y_train.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L205qPeQOB7B",
        "colab": {}
      },
      "source": [
        "#We are initializing weights and Bias of (Input-Hidden Layer)\n",
        "w1 = tf.random_normal(shape=(4,5))\n",
        "b1 = tf.zeros(shape=(5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8dMsZv8CfUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We are initializing weights and Bias of (Hidden-Output)\n",
        "w2 = tf.random_normal(shape=(5,1))\n",
        "b2 = tf.zeros(shape=(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HgtWA-UIOB7F"
      },
      "source": [
        "2.Define a function to calculate prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JveGlx25OB7H",
        "colab": {}
      },
      "source": [
        "def prediction(x, w1, b1,w2,b2):\n",
        "    \n",
        "    xw_matmul = tf.matmul(x, w1)\n",
        "    net1 = tf.add(xw_matmul, b1)\n",
        "    y=tf.sigmoid(net1)\n",
        "    net2=tf.matmul(y, w2)+b2\n",
        "    out=tf.sigmoid(net2)\n",
        "    return net2,out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TL1hIwf_OB7M"
      },
      "source": [
        "3.Loss (Cost) Function [Mean square error]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8VSWPiGXOB7P",
        "colab": {}
      },
      "source": [
        "def loss(predicted_y, desired_y):\n",
        "  return tf.reduce_mean(tf.square(predicted_y - desired_y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jzG85FUlOB7U"
      },
      "source": [
        "4.Function to train the Model\n",
        "\n",
        "1.   Record all the mathematical steps to calculate Loss\n",
        "2.   Calculate Gradients of Loss w.r.t weights and bias\n",
        "3.   Update Weights and Bias based on gradients and learning rate to minimize loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cj802w-3OB7X",
        "colab": {}
      },
      "source": [
        "def train(train_x, train_y, w1, b1,w2,b2, learning_rate=0.01):\n",
        "    \n",
        "    #Record mathematical operations on 'tape' to calculate loss\n",
        "    with tf.GradientTape() as t:\n",
        "        \n",
        "        t.watch([w1,b1,w2,b2])\n",
        "        \n",
        "        net2,current_prediction = prediction(train_x, w1, b1,w2,b2)\n",
        "        current_loss =loss(net2,train_y)\n",
        "    \n",
        "    #Calculate Gradients for Loss with respect to Weights and Bias\n",
        "    dw1,db1,dw2,db2 = t.gradient(current_loss,[w1, b1,w2,b2])\n",
        "    \n",
        "    #Update Weights at output layer\n",
        "    w2 = w2 - learning_rate*dw2\n",
        "    b2 = b2 - learning_rate*db2\n",
        "    \n",
        "     #Update Weights at hidden layer\n",
        "    w1 = w1 - learning_rate*dw1\n",
        "    b1 = b1 - learning_rate*db1\n",
        "    \n",
        "    return w1, b1,w2,b2,current_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xSypb_u8OB7e"
      },
      "source": [
        "## Train the model for 100 epochs \n",
        "1. Observe the training loss at every iteration\n",
        "2. Observe Train loss at every 5th iteration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DVvgj7eQOB7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "57b2cc08-d5ef-43b0-ee3b-c1ff65774456"
      },
      "source": [
        "    for i in range(100):\n",
        "        w1, b1,w2,b2,current_loss = train(X_train, y_train, w1, b1,w2,b2)\n",
        "        print(\"Loss at step {:d}: {:.3f}\".format(i, current_loss))      #Training loss at each iteration\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at step 0: 273.893\n",
            "Loss at step 1: 273.893\n",
            "Loss at step 2: 273.893\n",
            "Loss at step 3: 273.893\n",
            "Loss at step 4: 273.893\n",
            "Loss at step 5: 273.893\n",
            "Loss at step 6: 273.893\n",
            "Loss at step 7: 273.893\n",
            "Loss at step 8: 273.893\n",
            "Loss at step 9: 273.893\n",
            "Loss at step 10: 273.893\n",
            "Loss at step 11: 273.893\n",
            "Loss at step 12: 273.893\n",
            "Loss at step 13: 273.893\n",
            "Loss at step 14: 273.893\n",
            "Loss at step 15: 273.893\n",
            "Loss at step 16: 273.893\n",
            "Loss at step 17: 273.893\n",
            "Loss at step 18: 273.893\n",
            "Loss at step 19: 273.893\n",
            "Loss at step 20: 273.893\n",
            "Loss at step 21: 273.892\n",
            "Loss at step 22: 273.892\n",
            "Loss at step 23: 273.892\n",
            "Loss at step 24: 273.892\n",
            "Loss at step 25: 273.892\n",
            "Loss at step 26: 273.892\n",
            "Loss at step 27: 273.892\n",
            "Loss at step 28: 273.892\n",
            "Loss at step 29: 273.892\n",
            "Loss at step 30: 273.892\n",
            "Loss at step 31: 273.892\n",
            "Loss at step 32: 273.892\n",
            "Loss at step 33: 273.892\n",
            "Loss at step 34: 273.892\n",
            "Loss at step 35: 273.892\n",
            "Loss at step 36: 273.892\n",
            "Loss at step 37: 273.892\n",
            "Loss at step 38: 273.892\n",
            "Loss at step 39: 273.892\n",
            "Loss at step 40: 273.892\n",
            "Loss at step 41: 273.892\n",
            "Loss at step 42: 273.892\n",
            "Loss at step 43: 273.892\n",
            "Loss at step 44: 273.892\n",
            "Loss at step 45: 273.892\n",
            "Loss at step 46: 273.892\n",
            "Loss at step 47: 273.892\n",
            "Loss at step 48: 273.892\n",
            "Loss at step 49: 273.892\n",
            "Loss at step 50: 273.892\n",
            "Loss at step 51: 273.892\n",
            "Loss at step 52: 273.892\n",
            "Loss at step 53: 273.892\n",
            "Loss at step 54: 273.892\n",
            "Loss at step 55: 273.892\n",
            "Loss at step 56: 273.892\n",
            "Loss at step 57: 273.892\n",
            "Loss at step 58: 273.892\n",
            "Loss at step 59: 273.892\n",
            "Loss at step 60: 273.892\n",
            "Loss at step 61: 273.892\n",
            "Loss at step 62: 273.892\n",
            "Loss at step 63: 273.892\n",
            "Loss at step 64: 273.892\n",
            "Loss at step 65: 273.892\n",
            "Loss at step 66: 273.892\n",
            "Loss at step 67: 273.892\n",
            "Loss at step 68: 273.892\n",
            "Loss at step 69: 273.892\n",
            "Loss at step 70: 273.892\n",
            "Loss at step 71: 273.892\n",
            "Loss at step 72: 273.892\n",
            "Loss at step 73: 273.892\n",
            "Loss at step 74: 273.892\n",
            "Loss at step 75: 273.892\n",
            "Loss at step 76: 273.892\n",
            "Loss at step 77: 273.892\n",
            "Loss at step 78: 273.892\n",
            "Loss at step 79: 273.892\n",
            "Loss at step 80: 273.892\n",
            "Loss at step 81: 273.892\n",
            "Loss at step 82: 273.892\n",
            "Loss at step 83: 273.892\n",
            "Loss at step 84: 273.892\n",
            "Loss at step 85: 273.892\n",
            "Loss at step 86: 273.892\n",
            "Loss at step 87: 273.892\n",
            "Loss at step 88: 273.892\n",
            "Loss at step 89: 273.892\n",
            "Loss at step 90: 273.892\n",
            "Loss at step 91: 273.892\n",
            "Loss at step 92: 273.892\n",
            "Loss at step 93: 273.892\n",
            "Loss at step 94: 273.891\n",
            "Loss at step 95: 273.891\n",
            "Loss at step 96: 273.891\n",
            "Loss at step 97: 273.891\n",
            "Loss at step 98: 273.891\n",
            "Loss at step 99: 273.891\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOEdy4IED_vs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "e786603b-db8b-4ce4-bb83-c60f8d5dc6d1"
      },
      "source": [
        "j =0 \n",
        "for i in range(100):\n",
        "        j = j+1\n",
        "        w1, b1,w2,b2,current_loss = train(X_train, y_train, w1, b1,w2,b2)\n",
        "        if (j==5) :\n",
        "          print(\"Loss at step {:d}: {:.3f}\".format(i, current_loss))      #Training loss at each iteration\n",
        "          j=0"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at step 4: 273.891\n",
            "Loss at step 9: 273.891\n",
            "Loss at step 14: 273.891\n",
            "Loss at step 19: 273.891\n",
            "Loss at step 24: 273.891\n",
            "Loss at step 29: 273.891\n",
            "Loss at step 34: 273.891\n",
            "Loss at step 39: 273.891\n",
            "Loss at step 44: 273.891\n",
            "Loss at step 49: 273.891\n",
            "Loss at step 54: 273.891\n",
            "Loss at step 59: 273.891\n",
            "Loss at step 64: 273.891\n",
            "Loss at step 69: 273.890\n",
            "Loss at step 74: 273.890\n",
            "Loss at step 79: 273.890\n",
            "Loss at step 84: 273.890\n",
            "Loss at step 89: 273.890\n",
            "Loss at step 94: 273.890\n",
            "Loss at step 99: 273.890\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DOL2ncA1OB7q"
      },
      "source": [
        "### Get the shapes and values of W and b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZGvtyTeuOB7r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "628d79dc-295b-4270-e9a0-ec35d696d042"
      },
      "source": [
        "w1"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=27024, shape=(4, 5), dtype=float32, numpy=\n",
              "array([[ 0.56307197,  0.5974973 , -2.1882133 , -1.1882637 , -0.31819642],\n",
              "       [ 0.7504402 ,  0.18279804,  0.56548864,  0.7103052 ,  0.8293352 ],\n",
              "       [ 1.4857831 ,  0.44716352, -0.9485869 ,  0.62377375, -0.95944476],\n",
              "       [ 0.9408965 ,  0.4884783 ,  1.7927797 , -0.36954525, -0.09329645]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vhDtOv5UOB7x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7e8f4ecc-fd10-4e2e-c79b-a64320548aac"
      },
      "source": [
        "b1"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=27027, shape=(5,), dtype=float32, numpy=\n",
              "array([ 0.22770372,  0.02868305,  0.5783496 , -0.21160543,  0.30046493],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJc0nf_pC23v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "b25bf4db-3f6b-4c8b-e737-2a6bb8a1c635"
      },
      "source": [
        "w2"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=27018, shape=(5, 1), dtype=float32, numpy=\n",
              "array([[ 1.8857754 ],\n",
              "       [ 0.69347465],\n",
              "       [ 1.9949948 ],\n",
              "       [-0.04412334],\n",
              "       [ 1.142733  ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R92XEEd_C5Qj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bbe90753-77e5-46e3-820f-c7372b8c640c"
      },
      "source": [
        "b2"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=27021, shape=(1,), dtype=float32, numpy=array([1.7789539], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ERq9GOKKciho"
      },
      "source": [
        "### Model Prediction on 1st Examples in Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gKGvUWahcihp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69f4a703-4dbd-4a73-9d3a-883c813b1969"
      },
      "source": [
        "y_pred,_=prediction(X_test,w1,b1,w2,b2)\n",
        "y_pred"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=41447, shape=(300, 1), dtype=float32, numpy=\n",
              "array([[5.6059194],\n",
              "       [5.6078753],\n",
              "       [5.616567 ],\n",
              "       [5.6022005],\n",
              "       [5.632062 ],\n",
              "       [5.607492 ],\n",
              "       [5.603563 ],\n",
              "       [5.6115804],\n",
              "       [5.6055694],\n",
              "       [5.6105304],\n",
              "       [5.6089115],\n",
              "       [5.613599 ],\n",
              "       [5.6118126],\n",
              "       [5.611454 ],\n",
              "       [5.6085887],\n",
              "       [5.6100054],\n",
              "       [5.6247225],\n",
              "       [5.607809 ],\n",
              "       [5.6064663],\n",
              "       [5.618067 ],\n",
              "       [5.610692 ],\n",
              "       [5.612874 ],\n",
              "       [5.6042852],\n",
              "       [5.6040716],\n",
              "       [5.6032853],\n",
              "       [5.6084433],\n",
              "       [5.631293 ],\n",
              "       [5.618208 ],\n",
              "       [5.6409254],\n",
              "       [5.6383085],\n",
              "       [5.605815 ],\n",
              "       [5.6176395],\n",
              "       [5.6143527],\n",
              "       [5.609762 ],\n",
              "       [5.6254287],\n",
              "       [5.611258 ],\n",
              "       [5.613589 ],\n",
              "       [5.6047726],\n",
              "       [5.6164684],\n",
              "       [5.619207 ],\n",
              "       [5.6139736],\n",
              "       [5.6036253],\n",
              "       [5.6130733],\n",
              "       [5.619395 ],\n",
              "       [5.6022124],\n",
              "       [5.6049895],\n",
              "       [5.6216946],\n",
              "       [5.608962 ],\n",
              "       [5.626375 ],\n",
              "       [5.6073585],\n",
              "       [5.6435003],\n",
              "       [5.6187034],\n",
              "       [5.6129045],\n",
              "       [5.614731 ],\n",
              "       [5.6120787],\n",
              "       [5.615108 ],\n",
              "       [5.607964 ],\n",
              "       [5.609543 ],\n",
              "       [5.6320353],\n",
              "       [5.6046124],\n",
              "       [5.6142883],\n",
              "       [5.602901 ],\n",
              "       [5.6177635],\n",
              "       [5.6188774],\n",
              "       [5.6114187],\n",
              "       [5.6122756],\n",
              "       [5.6124334],\n",
              "       [5.6202645],\n",
              "       [5.607765 ],\n",
              "       [5.613056 ],\n",
              "       [5.6074724],\n",
              "       [5.6042795],\n",
              "       [5.612459 ],\n",
              "       [5.6288233],\n",
              "       [5.6092286],\n",
              "       [5.611327 ],\n",
              "       [5.608604 ],\n",
              "       [5.603812 ],\n",
              "       [5.615157 ],\n",
              "       [5.611986 ],\n",
              "       [5.6104207],\n",
              "       [5.6232295],\n",
              "       [5.649747 ],\n",
              "       [5.6057487],\n",
              "       [5.6263614],\n",
              "       [5.6036353],\n",
              "       [5.6036725],\n",
              "       [5.6055746],\n",
              "       [5.6049633],\n",
              "       [5.6039615],\n",
              "       [5.6041565],\n",
              "       [5.60689  ],\n",
              "       [5.6280613],\n",
              "       [5.6085477],\n",
              "       [5.6243706],\n",
              "       [5.607174 ],\n",
              "       [5.6102047],\n",
              "       [5.6073575],\n",
              "       [5.615843 ],\n",
              "       [5.64617  ],\n",
              "       [5.614208 ],\n",
              "       [5.6061325],\n",
              "       [5.607615 ],\n",
              "       [5.626429 ],\n",
              "       [5.6087894],\n",
              "       [5.6091614],\n",
              "       [5.6093645],\n",
              "       [5.6136084],\n",
              "       [5.607389 ],\n",
              "       [5.6151505],\n",
              "       [5.607157 ],\n",
              "       [5.6110783],\n",
              "       [5.6278586],\n",
              "       [5.6045775],\n",
              "       [5.6031876],\n",
              "       [5.60728  ],\n",
              "       [5.617467 ],\n",
              "       [5.633458 ],\n",
              "       [5.6079335],\n",
              "       [5.6058807],\n",
              "       [5.6138515],\n",
              "       [5.6146264],\n",
              "       [5.604371 ],\n",
              "       [5.603349 ],\n",
              "       [5.6105556],\n",
              "       [5.607614 ],\n",
              "       [5.6268873],\n",
              "       [5.61266  ],\n",
              "       [5.6092386],\n",
              "       [5.607068 ],\n",
              "       [5.6249895],\n",
              "       [5.6177745],\n",
              "       [5.610999 ],\n",
              "       [5.6080227],\n",
              "       [5.6073756],\n",
              "       [5.605261 ],\n",
              "       [5.6201706],\n",
              "       [5.603738 ],\n",
              "       [5.6237106],\n",
              "       [5.641468 ],\n",
              "       [5.606385 ],\n",
              "       [5.618951 ],\n",
              "       [5.607567 ],\n",
              "       [5.615527 ],\n",
              "       [5.603055 ],\n",
              "       [5.6034646],\n",
              "       [5.606118 ],\n",
              "       [5.6102953],\n",
              "       [5.6140347],\n",
              "       [5.604186 ],\n",
              "       [5.6111965],\n",
              "       [5.60419  ],\n",
              "       [5.602095 ],\n",
              "       [5.606642 ],\n",
              "       [5.61871  ],\n",
              "       [5.613763 ],\n",
              "       [5.605806 ],\n",
              "       [5.60291  ],\n",
              "       [5.6224184],\n",
              "       [5.6028414],\n",
              "       [5.607677 ],\n",
              "       [5.6046762],\n",
              "       [5.6143723],\n",
              "       [5.604166 ],\n",
              "       [5.6063347],\n",
              "       [5.6106353],\n",
              "       [5.604453 ],\n",
              "       [5.6087723],\n",
              "       [5.609612 ],\n",
              "       [5.6120667],\n",
              "       [5.6027384],\n",
              "       [5.611222 ],\n",
              "       [5.61072  ],\n",
              "       [5.610994 ],\n",
              "       [5.6143723],\n",
              "       [5.609235 ],\n",
              "       [5.6122847],\n",
              "       [5.61114  ],\n",
              "       [5.6237574],\n",
              "       [5.6081266],\n",
              "       [5.611948 ],\n",
              "       [5.607758 ],\n",
              "       [5.605763 ],\n",
              "       [5.611849 ],\n",
              "       [5.604698 ],\n",
              "       [5.6101847],\n",
              "       [5.6253366],\n",
              "       [5.6166477],\n",
              "       [5.6218376],\n",
              "       [5.620433 ],\n",
              "       [5.6093473],\n",
              "       [5.608098 ],\n",
              "       [5.608899 ],\n",
              "       [5.607011 ],\n",
              "       [5.6082826],\n",
              "       [5.610407 ],\n",
              "       [5.6105785],\n",
              "       [5.625505 ],\n",
              "       [5.6042194],\n",
              "       [5.6071887],\n",
              "       [5.6141715],\n",
              "       [5.6144323],\n",
              "       [5.611463 ],\n",
              "       [5.6018295],\n",
              "       [5.612484 ],\n",
              "       [5.605567 ],\n",
              "       [5.612088 ],\n",
              "       [5.6068325],\n",
              "       [5.6088715],\n",
              "       [5.621027 ],\n",
              "       [5.611987 ],\n",
              "       [5.605695 ],\n",
              "       [5.604493 ],\n",
              "       [5.6037407],\n",
              "       [5.6045594],\n",
              "       [5.603758 ],\n",
              "       [5.6047497],\n",
              "       [5.6081862],\n",
              "       [5.6212378],\n",
              "       [5.605973 ],\n",
              "       [5.6092634],\n",
              "       [5.6164494],\n",
              "       [5.6101894],\n",
              "       [5.6081495],\n",
              "       [5.6089973],\n",
              "       [5.6113276],\n",
              "       [5.62162  ],\n",
              "       [5.6032667],\n",
              "       [5.6063566],\n",
              "       [5.6217384],\n",
              "       [5.602974 ],\n",
              "       [5.617964 ],\n",
              "       [5.614763 ],\n",
              "       [5.6205273],\n",
              "       [5.6229763],\n",
              "       [5.6249876],\n",
              "       [5.60987  ],\n",
              "       [5.606446 ],\n",
              "       [5.6052437],\n",
              "       [5.6120257],\n",
              "       [5.606141 ],\n",
              "       [5.6228995],\n",
              "       [5.613159 ],\n",
              "       [5.615624 ],\n",
              "       [5.603447 ],\n",
              "       [5.6094   ],\n",
              "       [5.613768 ],\n",
              "       [5.6174603],\n",
              "       [5.609066 ],\n",
              "       [5.6065435],\n",
              "       [5.613639 ],\n",
              "       [5.669138 ],\n",
              "       [5.6087117],\n",
              "       [5.630224 ],\n",
              "       [5.6088686],\n",
              "       [5.6022167],\n",
              "       [5.60738  ],\n",
              "       [5.605239 ],\n",
              "       [5.6173673],\n",
              "       [5.6099586],\n",
              "       [5.6182337],\n",
              "       [5.6101193],\n",
              "       [5.6251554],\n",
              "       [5.6038055],\n",
              "       [5.6039915],\n",
              "       [5.620916 ],\n",
              "       [5.604109 ],\n",
              "       [5.627594 ],\n",
              "       [5.6079226],\n",
              "       [5.606049 ],\n",
              "       [5.613811 ],\n",
              "       [5.6102266],\n",
              "       [5.614662 ],\n",
              "       [5.6181903],\n",
              "       [5.607626 ],\n",
              "       [5.611999 ],\n",
              "       [5.6052547],\n",
              "       [5.6169424],\n",
              "       [5.621194 ],\n",
              "       [5.6076813],\n",
              "       [5.6147146],\n",
              "       [5.603703 ],\n",
              "       [5.6047354],\n",
              "       [5.606531 ],\n",
              "       [5.6070356],\n",
              "       [5.6049976],\n",
              "       [5.6083965],\n",
              "       [5.6057024],\n",
              "       [5.6186523],\n",
              "       [5.6163692],\n",
              "       [5.63127  ],\n",
              "       [5.6163673],\n",
              "       [5.6966567],\n",
              "       [5.604141 ],\n",
              "       [5.602432 ],\n",
              "       [5.6374836],\n",
              "       [5.6049905],\n",
              "       [5.621477 ],\n",
              "       [5.6072435],\n",
              "       [5.618244 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqm2QTNuHXs-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "92b4f3f2-c1cb-45c8-c44d-e8336dee0390"
      },
      "source": [
        "y_test - y_pred"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=41450, shape=(300, 300), dtype=float32, numpy=\n",
              "array([[-0.7065191 , -4.7830195 , -4.3777194 , ..., -2.2190194 ,\n",
              "        -3.9351194 , -1.5943193 ],\n",
              "       [-0.7084751 , -4.7849755 , -4.3796754 , ..., -2.2209754 ,\n",
              "        -3.9370754 , -1.5962753 ],\n",
              "       [-0.7171669 , -4.7936673 , -4.388367  , ..., -2.2296672 ,\n",
              "        -3.9457672 , -1.6049671 ],\n",
              "       ...,\n",
              "       [-0.7220769 , -4.7985773 , -4.393277  , ..., -2.2345772 ,\n",
              "        -3.9506772 , -1.6098771 ],\n",
              "       [-0.7078433 , -4.7843437 , -4.3790436 , ..., -2.2203436 ,\n",
              "        -3.9364436 , -1.5956435 ],\n",
              "       [-0.71884394, -4.7953444 , -4.390044  , ..., -2.2313442 ,\n",
              "        -3.9474442 , -1.6066442 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD1eZYmeHe7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o77k0ImpHobb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e88d4e16-7acd-4a9f-96ba-09741ecf699e"
      },
      "source": [
        "cm=metrics.r2_score(y_test,y_pred)\n",
        "print(cm)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.016481337564543397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YJRBuqXhOB7_"
      },
      "source": [
        "## Classification using tf.Keras\n",
        "\n",
        "In this exercise, we will build a Deep Neural Network using tf.Keras. We will use Iris Dataset for this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O0g6lorycihf"
      },
      "source": [
        "### Load the given Iris data using pandas (Iris.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6xFvb5sRcihg",
        "colab": {}
      },
      "source": [
        "iris = pd.read_csv('/content/drive/My Drive/Internal Lab-6/11_Iris.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeI5Qcs9Isnx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "432bda90-d2c3-424e-b61e-8578cd32c371"
      },
      "source": [
        "iris.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_khBfHYIw4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "f879594c-7c1c-4da9-e8d8-e29c45aef5cb"
      },
      "source": [
        "iris.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SAB--Qdwcihm"
      },
      "source": [
        "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IJr5dYnocihm",
        "colab": {}
      },
      "source": [
        "iris = pd.get_dummies(iris, columns=[\"Species\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgPtToF0LBVV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "3abf5742-759d-4c06-87b3-7b3e251f265f"
      },
      "source": [
        "iris.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species_Iris-setosa</th>\n",
              "      <th>Species_Iris-versicolor</th>\n",
              "      <th>Species_Iris-virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  SepalLengthCm  ...  Species_Iris-versicolor  Species_Iris-virginica\n",
              "0   1            5.1  ...                        0                       0\n",
              "1   2            4.9  ...                        0                       0\n",
              "2   3            4.7  ...                        0                       0\n",
              "3   4            4.6  ...                        0                       0\n",
              "4   5            5.0  ...                        0                       0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D95nY5ILcihj"
      },
      "source": [
        "### Splitting the data into feature set and target set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RyMQoLMucihj",
        "colab": {}
      },
      "source": [
        "X = iris.drop([\"Id\", \"Species_Iris-setosa\", \"Species_Iris-versicolor\", \"Species_Iris-virginica\"], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsCVBMg-Llij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = iris[[\"Species_Iris-setosa\", \"Species_Iris-versicolor\", \"Species_Iris-virginica\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b22qpC5xcihr"
      },
      "source": [
        "###  Building Model in tf.keras\n",
        "\n",
        "Build a Linear Classifier model  <br>\n",
        "1.  Use Dense Layer  with input shape of 4 (according to the feature set) and number of outputs set to 3<br> \n",
        "2. Apply Softmax on Dense Layer outputs <br>\n",
        "3. Use SGD as Optimizer\n",
        "4. Use categorical_crossentropy as loss function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JklAatiaSR1D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hov_UFnUciht",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# define base model\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Dense(4, input_dim=4, kernel_initializer='normal', activation='relu')) # first value 13 - number of neurons in first hidden layer can be anyhting - 10, 8 \n",
        "model.add(tf.keras.layers.Dense(3, kernel_initializer='normal', activation=\"softmax\")) #last dense id treated as output layer # regression always one output , but for classification for binary we can have onr ouput but for multiclass we would have 2-3 outputs due to one hot encoding  \n",
        "# Compile model\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy',tf.keras.metrics.CategoricalAccuracy()])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T5FdzqIKcihw"
      },
      "source": [
        "### Model Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki_gIN9bQbdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.30,random_state = 7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W74tNlTgf1RP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U301AFiOSm5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62d17137-d1af-484b-d3ee-66493cd89fe2"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4qLEdHPscihx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a363946-58fe-4e25-ff2c-08357d999275"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50)\n",
        "          "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <type 'NoneType'>\n",
            "Train on 105 samples, validate on 45 samples\n",
            "Epoch 1/50\n",
            "105/105 [==============================] - 0s 1ms/sample - loss: 1.0978 - accuracy: 0.3238 - categorical_accuracy: 0.3238 - val_loss: 1.0976 - val_accuracy: 0.4444 - val_categorical_accuracy: 0.4444\n",
            "Epoch 2/50\n",
            "105/105 [==============================] - 0s 116us/sample - loss: 1.0975 - accuracy: 0.4857 - categorical_accuracy: 0.4857 - val_loss: 1.0974 - val_accuracy: 0.5778 - val_categorical_accuracy: 0.5778\n",
            "Epoch 3/50\n",
            "105/105 [==============================] - 0s 117us/sample - loss: 1.0974 - accuracy: 0.5714 - categorical_accuracy: 0.5714 - val_loss: 1.0975 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 4/50\n",
            "105/105 [==============================] - 0s 131us/sample - loss: 1.0974 - accuracy: 0.6857 - categorical_accuracy: 0.6857 - val_loss: 1.0973 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 5/50\n",
            "105/105 [==============================] - 0s 122us/sample - loss: 1.0972 - accuracy: 0.6857 - categorical_accuracy: 0.6857 - val_loss: 1.0969 - val_accuracy: 0.4444 - val_categorical_accuracy: 0.4444\n",
            "Epoch 6/50\n",
            "105/105 [==============================] - 0s 114us/sample - loss: 1.0971 - accuracy: 0.4286 - categorical_accuracy: 0.4286 - val_loss: 1.0970 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 7/50\n",
            "105/105 [==============================] - 0s 122us/sample - loss: 1.0968 - accuracy: 0.6857 - categorical_accuracy: 0.6857 - val_loss: 1.0971 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 8/50\n",
            "105/105 [==============================] - 0s 95us/sample - loss: 1.0966 - accuracy: 0.6476 - categorical_accuracy: 0.6476 - val_loss: 1.0969 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 9/50\n",
            "105/105 [==============================] - 0s 93us/sample - loss: 1.0964 - accuracy: 0.6476 - categorical_accuracy: 0.6476 - val_loss: 1.0968 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 10/50\n",
            "105/105 [==============================] - 0s 110us/sample - loss: 1.0962 - accuracy: 0.6476 - categorical_accuracy: 0.6476 - val_loss: 1.0966 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 11/50\n",
            "105/105 [==============================] - 0s 102us/sample - loss: 1.0961 - accuracy: 0.6667 - categorical_accuracy: 0.6667 - val_loss: 1.0967 - val_accuracy: 0.3333 - val_categorical_accuracy: 0.3333\n",
            "Epoch 12/50\n",
            "105/105 [==============================] - 0s 111us/sample - loss: 1.0958 - accuracy: 0.4476 - categorical_accuracy: 0.4476 - val_loss: 1.0965 - val_accuracy: 0.3333 - val_categorical_accuracy: 0.3333\n",
            "Epoch 13/50\n",
            "105/105 [==============================] - 0s 101us/sample - loss: 1.0955 - accuracy: 0.4857 - categorical_accuracy: 0.4857 - val_loss: 1.0962 - val_accuracy: 0.3333 - val_categorical_accuracy: 0.3333\n",
            "Epoch 14/50\n",
            "105/105 [==============================] - 0s 115us/sample - loss: 1.0953 - accuracy: 0.4571 - categorical_accuracy: 0.4571 - val_loss: 1.0960 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 15/50\n",
            "105/105 [==============================] - 0s 123us/sample - loss: 1.0949 - accuracy: 0.6762 - categorical_accuracy: 0.6762 - val_loss: 1.0956 - val_accuracy: 0.4000 - val_categorical_accuracy: 0.4000\n",
            "Epoch 16/50\n",
            "105/105 [==============================] - 0s 129us/sample - loss: 1.0947 - accuracy: 0.4667 - categorical_accuracy: 0.4667 - val_loss: 1.0954 - val_accuracy: 0.3333 - val_categorical_accuracy: 0.3333\n",
            "Epoch 17/50\n",
            "105/105 [==============================] - 0s 134us/sample - loss: 1.0943 - accuracy: 0.4571 - categorical_accuracy: 0.4571 - val_loss: 1.0951 - val_accuracy: 0.4222 - val_categorical_accuracy: 0.4222\n",
            "Epoch 18/50\n",
            "105/105 [==============================] - 0s 132us/sample - loss: 1.0940 - accuracy: 0.5143 - categorical_accuracy: 0.5143 - val_loss: 1.0947 - val_accuracy: 0.6000 - val_categorical_accuracy: 0.6000\n",
            "Epoch 19/50\n",
            "105/105 [==============================] - 0s 137us/sample - loss: 1.0936 - accuracy: 0.6095 - categorical_accuracy: 0.6095 - val_loss: 1.0942 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 20/50\n",
            "105/105 [==============================] - 0s 114us/sample - loss: 1.0932 - accuracy: 0.6857 - categorical_accuracy: 0.6857 - val_loss: 1.0942 - val_accuracy: 0.5778 - val_categorical_accuracy: 0.5778\n",
            "Epoch 21/50\n",
            "105/105 [==============================] - 0s 137us/sample - loss: 1.0928 - accuracy: 0.5905 - categorical_accuracy: 0.5905 - val_loss: 1.0938 - val_accuracy: 0.5111 - val_categorical_accuracy: 0.5111\n",
            "Epoch 22/50\n",
            "105/105 [==============================] - 0s 116us/sample - loss: 1.0923 - accuracy: 0.5429 - categorical_accuracy: 0.5429 - val_loss: 1.0936 - val_accuracy: 0.6000 - val_categorical_accuracy: 0.6000\n",
            "Epoch 23/50\n",
            "105/105 [==============================] - 0s 117us/sample - loss: 1.0918 - accuracy: 0.6190 - categorical_accuracy: 0.6190 - val_loss: 1.0930 - val_accuracy: 0.6000 - val_categorical_accuracy: 0.6000\n",
            "Epoch 24/50\n",
            "105/105 [==============================] - 0s 105us/sample - loss: 1.0913 - accuracy: 0.6190 - categorical_accuracy: 0.6190 - val_loss: 1.0923 - val_accuracy: 0.6000 - val_categorical_accuracy: 0.6000\n",
            "Epoch 25/50\n",
            "105/105 [==============================] - 0s 106us/sample - loss: 1.0907 - accuracy: 0.6000 - categorical_accuracy: 0.6000 - val_loss: 1.0918 - val_accuracy: 0.6000 - val_categorical_accuracy: 0.6000\n",
            "Epoch 26/50\n",
            "105/105 [==============================] - 0s 125us/sample - loss: 1.0900 - accuracy: 0.6286 - categorical_accuracy: 0.6286 - val_loss: 1.0911 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 27/50\n",
            "105/105 [==============================] - 0s 112us/sample - loss: 1.0894 - accuracy: 0.6571 - categorical_accuracy: 0.6571 - val_loss: 1.0903 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 28/50\n",
            "105/105 [==============================] - 0s 116us/sample - loss: 1.0887 - accuracy: 0.6476 - categorical_accuracy: 0.6476 - val_loss: 1.0891 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 29/50\n",
            "105/105 [==============================] - 0s 115us/sample - loss: 1.0879 - accuracy: 0.6857 - categorical_accuracy: 0.6857 - val_loss: 1.0885 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 30/50\n",
            "105/105 [==============================] - 0s 131us/sample - loss: 1.0871 - accuracy: 0.6857 - categorical_accuracy: 0.6857 - val_loss: 1.0875 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 31/50\n",
            "105/105 [==============================] - 0s 129us/sample - loss: 1.0862 - accuracy: 0.6952 - categorical_accuracy: 0.6952 - val_loss: 1.0868 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 32/50\n",
            "105/105 [==============================] - 0s 177us/sample - loss: 1.0853 - accuracy: 0.6857 - categorical_accuracy: 0.6857 - val_loss: 1.0855 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 33/50\n",
            "105/105 [==============================] - 0s 134us/sample - loss: 1.0843 - accuracy: 0.6857 - categorical_accuracy: 0.6857 - val_loss: 1.0845 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 34/50\n",
            "105/105 [==============================] - 0s 153us/sample - loss: 1.0833 - accuracy: 0.6857 - categorical_accuracy: 0.6857 - val_loss: 1.0831 - val_accuracy: 0.6222 - val_categorical_accuracy: 0.6222\n",
            "Epoch 35/50\n",
            "105/105 [==============================] - 0s 115us/sample - loss: 1.0821 - accuracy: 0.6857 - categorical_accuracy: 0.6857 - val_loss: 1.0820 - val_accuracy: 0.8667 - val_categorical_accuracy: 0.8667\n",
            "Epoch 36/50\n",
            "105/105 [==============================] - 0s 195us/sample - loss: 1.0808 - accuracy: 0.8952 - categorical_accuracy: 0.8952 - val_loss: 1.0807 - val_accuracy: 0.8667 - val_categorical_accuracy: 0.8667\n",
            "Epoch 37/50\n",
            "105/105 [==============================] - 0s 110us/sample - loss: 1.0796 - accuracy: 0.9238 - categorical_accuracy: 0.9238 - val_loss: 1.0797 - val_accuracy: 0.8667 - val_categorical_accuracy: 0.8667\n",
            "Epoch 38/50\n",
            "105/105 [==============================] - 0s 124us/sample - loss: 1.0784 - accuracy: 0.8286 - categorical_accuracy: 0.8286 - val_loss: 1.0779 - val_accuracy: 0.7333 - val_categorical_accuracy: 0.7333\n",
            "Epoch 39/50\n",
            "105/105 [==============================] - 0s 145us/sample - loss: 1.0768 - accuracy: 0.7524 - categorical_accuracy: 0.7524 - val_loss: 1.0768 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n",
            "Epoch 40/50\n",
            "105/105 [==============================] - 0s 114us/sample - loss: 1.0752 - accuracy: 0.6857 - categorical_accuracy: 0.6857 - val_loss: 1.0749 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n",
            "Epoch 41/50\n",
            "105/105 [==============================] - 0s 118us/sample - loss: 1.0737 - accuracy: 0.6952 - categorical_accuracy: 0.6952 - val_loss: 1.0721 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n",
            "Epoch 42/50\n",
            "105/105 [==============================] - 0s 129us/sample - loss: 1.0718 - accuracy: 0.6762 - categorical_accuracy: 0.6762 - val_loss: 1.0702 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n",
            "Epoch 43/50\n",
            "105/105 [==============================] - 0s 123us/sample - loss: 1.0700 - accuracy: 0.6762 - categorical_accuracy: 0.6762 - val_loss: 1.0679 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n",
            "Epoch 44/50\n",
            "105/105 [==============================] - 0s 122us/sample - loss: 1.0680 - accuracy: 0.6762 - categorical_accuracy: 0.6762 - val_loss: 1.0665 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n",
            "Epoch 45/50\n",
            "105/105 [==============================] - 0s 116us/sample - loss: 1.0658 - accuracy: 0.6762 - categorical_accuracy: 0.6762 - val_loss: 1.0640 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n",
            "Epoch 46/50\n",
            "105/105 [==============================] - 0s 125us/sample - loss: 1.0637 - accuracy: 0.6762 - categorical_accuracy: 0.6762 - val_loss: 1.0611 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n",
            "Epoch 47/50\n",
            "105/105 [==============================] - 0s 114us/sample - loss: 1.0612 - accuracy: 0.6762 - categorical_accuracy: 0.6762 - val_loss: 1.0576 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n",
            "Epoch 48/50\n",
            "105/105 [==============================] - 0s 113us/sample - loss: 1.0587 - accuracy: 0.6762 - categorical_accuracy: 0.6762 - val_loss: 1.0541 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n",
            "Epoch 49/50\n",
            "105/105 [==============================] - 0s 113us/sample - loss: 1.0559 - accuracy: 0.6762 - categorical_accuracy: 0.6762 - val_loss: 1.0514 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n",
            "Epoch 50/50\n",
            "105/105 [==============================] - 0s 108us/sample - loss: 1.0535 - accuracy: 0.6762 - categorical_accuracy: 0.6762 - val_loss: 1.0485 - val_accuracy: 0.6444 - val_categorical_accuracy: 0.6444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcdffa7b310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y-SgSSdRcih5"
      },
      "source": [
        "### Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GBgKZkhkcih6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "outputId": "ac2e4149-2935-4655-99bd-a28b5af712b7"
      },
      "source": [
        "output = model.predict(X_test)\n",
        "print(output)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <type 'NoneType'>\n",
            "[[0.29594827 0.34681228 0.3572395 ]\n",
            " [0.3045472  0.34395152 0.35150123]\n",
            " [0.34537297 0.32965878 0.32496822]\n",
            " [0.30390978 0.3441655  0.3519247 ]\n",
            " [0.30237675 0.34467888 0.35294437]\n",
            " [0.34024203 0.33151534 0.3282426 ]\n",
            " [0.2967321  0.3465538  0.35671407]\n",
            " [0.30611444 0.3434242  0.35046136]\n",
            " [0.34317085 0.33045763 0.32637158]\n",
            " [0.30243337 0.34465995 0.35290667]\n",
            " [0.29486743 0.34716785 0.35796478]\n",
            " [0.30423015 0.344058   0.3517118 ]\n",
            " [0.34735245 0.32893825 0.32370937]\n",
            " [0.2825341  0.3511596  0.3663063 ]\n",
            " [0.3437408  0.33025116 0.32600808]\n",
            " [0.2996902  0.3455743  0.35473558]\n",
            " [0.28468716 0.35047165 0.36484122]\n",
            " [0.29136035 0.34831533 0.36032438]\n",
            " [0.3444313  0.33000073 0.32556793]\n",
            " [0.34266773 0.33063972 0.3266926 ]\n",
            " [0.30875373 0.34253207 0.34871426]\n",
            " [0.2859278  0.35007346 0.36399874]\n",
            " [0.30052823 0.34529555 0.35417622]\n",
            " [0.29392526 0.34747705 0.35859773]\n",
            " [0.2867845  0.3497978  0.3634177 ]\n",
            " [0.29831436 0.34603068 0.35565495]\n",
            " [0.30436406 0.34401307 0.35162288]\n",
            " [0.30956215 0.34225774 0.3481801 ]\n",
            " [0.29414698 0.34740436 0.3584487 ]\n",
            " [0.28637406 0.34992993 0.36369598]\n",
            " [0.29662776 0.34658822 0.356784  ]\n",
            " [0.3133039  0.34098214 0.345714  ]\n",
            " [0.35079977 0.3276776  0.32152262]\n",
            " [0.2890966  0.3490508  0.3618526 ]\n",
            " [0.30372685 0.34422687 0.35204628]\n",
            " [0.3422406  0.33079413 0.32696524]\n",
            " [0.34425637 0.3300642  0.3256794 ]\n",
            " [0.34186158 0.3309311  0.32720733]\n",
            " [0.34406897 0.3301322  0.32579887]\n",
            " [0.28359    0.3508227  0.36558732]\n",
            " [0.2881179  0.34936753 0.3625146 ]\n",
            " [0.29689386 0.34650043 0.35660574]\n",
            " [0.2868009  0.34979254 0.36340663]\n",
            " [0.29052764 0.34858635 0.36088604]\n",
            " [0.30795607 0.34280223 0.34924173]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys5ukZEIcRC4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdad9dfa-3b61-428d-fc93-53ef2dec8585"
      },
      "source": [
        "output.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjySn-voaUFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "86665b96-2e24-48c5-e862-74cba203aa45"
      },
      "source": [
        "#y_t = np.argmax(y_test, axis = 1)\n",
        "y_pred = np.argmax(output, axis = 1)\n",
        "y_pred"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 0, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 2, 0, 2, 2, 2, 0, 0, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 2, 2, 2, 2, 2,\n",
              "       2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P32ASP1Vjt0a"
      },
      "source": [
        "### Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8rd0jjAjyTR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "6241d8e2-31c1-41cc-915f-17c2c22504d6"
      },
      "source": [
        "model.save(\"Iris.html\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-2.0.0/python2.7/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: Iris.html/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XiipRpe7rbVh"
      },
      "source": [
        "### Build and Train a Deep Neural network with 2 hidden layer  - Optional - For Practice\n",
        "\n",
        "Does it perform better than Linear Classifier? What could be the reason for difference in performance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v5Du3lubr4sA",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}